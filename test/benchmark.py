#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é‚®ç®±æœåŠ¡å™¨åŸºå‡†æµ‹è¯•å·¥å…·
ç»¼åˆæµ‹è¯•APIæ€§èƒ½ã€é‚®ä»¶å¤„ç†èƒ½åŠ›å’Œç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
"""

import requests
import time
import threading
import queue
import statistics
import json
import os
import sys
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import subprocess
import psutil

class MailServerBenchmark:
    def __init__(self, base_url="http://localhost:9090"):
        self.base_url = base_url
        self.results = {
            "api_tests": [],
            "email_tests": [],
            "concurrent_tests": [],
            "resource_usage": [],
            "summary": {}
        }
        self.start_time = time.time()
        
    def log(self, message, level="INFO"):
        """æ—¥å¿—è¾“å‡º"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {level}: {message}")
        
    def measure_response_time(self, func, *args, **kwargs):
        """æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´"""
        start_time = time.time()
        try:
            result = func(*args, **kwargs)
            end_time = time.time()
            return (end_time - start_time) * 1000, True, result, None
        except Exception as e:
            end_time = time.time()
            return (end_time - start_time) * 1000, False, None, str(e)
    
    def test_api_endpoint(self, endpoint, method="GET", data=None, iterations=10):
        """æµ‹è¯•APIç«¯ç‚¹æ€§èƒ½"""
        self.log(f"ğŸ” æµ‹è¯•APIç«¯ç‚¹: {method} {endpoint} ({iterations}æ¬¡)")
        
        response_times = []
        success_count = 0
        error_count = 0
        errors = []
        
        for i in range(iterations):
            url = f"{self.base_url}{endpoint}"
            
            if method.upper() == "GET":
                response_time, success, result, error = self.measure_response_time(
                    requests.get, url, timeout=10
                )
            elif method.upper() == "POST":
                response_time, success, result, error = self.measure_response_time(
                    requests.post, url, json=data, timeout=10
                )
            else:
                continue
                
            response_times.append(response_time)
            
            if success and result.status_code == 200:
                success_count += 1
                print(f"âœ… è¯·æ±‚{i+1}: {response_time:.2f}ms")
            else:
                error_count += 1
                error_msg = error or f"HTTP {result.status_code if result else 'Unknown'}"
                errors.append(error_msg)
                print(f"âŒ è¯·æ±‚{i+1}: {response_time:.2f}ms - {error_msg}")
            
            time.sleep(0.1)  # é¿å…è¿‡åº¦è¯·æ±‚
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_time = statistics.mean(response_times)
        min_time = min(response_times)
        max_time = max(response_times)
        median_time = statistics.median(response_times)
        
        test_result = {
            "endpoint": endpoint,
            "method": method,
            "iterations": iterations,
            "success_count": success_count,
            "error_count": error_count,
            "success_rate": (success_count / iterations) * 100,
            "avg_response_time": avg_time,
            "min_response_time": min_time,
            "max_response_time": max_time,
            "median_response_time": median_time,
            "errors": errors[:5]  # åªä¿ç•™å‰5ä¸ªé”™è¯¯
        }
        
        self.results["api_tests"].append(test_result)
        
        self.log(f"ğŸ“Š ç»“æœ: æˆåŠŸç‡ {test_result['success_rate']:.1f}%, "
                f"å¹³å‡å“åº”æ—¶é—´ {avg_time:.2f}ms")
        
        return test_result
    
    def test_concurrent_requests(self, endpoint, concurrent_users=10, requests_per_user=5):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚æ€§èƒ½"""
        self.log(f"ğŸš€ å¹¶å‘æµ‹è¯•: {concurrent_users}ä¸ªç”¨æˆ·, æ¯ç”¨æˆ·{requests_per_user}ä¸ªè¯·æ±‚")
        
        total_requests = concurrent_users * requests_per_user
        response_times = []
        success_count = 0
        error_count = 0
        start_time = time.time()
        
        def worker(user_id):
            """å·¥ä½œçº¿ç¨‹å‡½æ•°"""
            user_results = []
            for i in range(requests_per_user):
                url = f"{self.base_url}{endpoint}"
                response_time, success, result, error = self.measure_response_time(
                    requests.get, url, timeout=10
                )
                
                user_results.append({
                    "user_id": user_id,
                    "request_id": i + 1,
                    "response_time": response_time,
                    "success": success,
                    "error": error
                })
                
                time.sleep(0.05)  # çŸ­æš‚å»¶è¿Ÿ
            
            return user_results
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¹¶å‘è¯·æ±‚
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(worker, i+1) for i in range(concurrent_users)]
            
            for future in as_completed(futures):
                user_results = future.result()
                for result in user_results:
                    response_times.append(result["response_time"])
                    if result["success"]:
                        success_count += 1
                    else:
                        error_count += 1
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_time = statistics.mean(response_times)
        throughput = total_requests / total_time
        
        concurrent_result = {
            "endpoint": endpoint,
            "concurrent_users": concurrent_users,
            "requests_per_user": requests_per_user,
            "total_requests": total_requests,
            "total_time": total_time,
            "success_count": success_count,
            "error_count": error_count,
            "success_rate": (success_count / total_requests) * 100,
            "avg_response_time": avg_time,
            "throughput": throughput,
            "min_response_time": min(response_times),
            "max_response_time": max(response_times)
        }
        
        self.results["concurrent_tests"].append(concurrent_result)
        
        self.log(f"ğŸ“Š å¹¶å‘ç»“æœ: æˆåŠŸç‡ {concurrent_result['success_rate']:.1f}%, "
                f"ååé‡ {throughput:.2f} req/s, å¹³å‡å“åº”æ—¶é—´ {avg_time:.2f}ms")
        
        return concurrent_result
    
    def test_email_sending(self, iterations=5):
        """æµ‹è¯•é‚®ä»¶å‘é€æ€§èƒ½"""
        self.log(f"ğŸ“§ æµ‹è¯•é‚®ä»¶å‘é€æ€§èƒ½ ({iterations}æ¬¡)")
        
        response_times = []
        success_count = 0
        error_count = 0
        
        for i in range(iterations):
            email_data = {
                "from": "test@ygocard.org",
                "to": "recipient@example.com",
                "subject": f"åŸºå‡†æµ‹è¯•é‚®ä»¶ {i+1}",
                "body": f"è¿™æ˜¯ç¬¬{i+1}å°åŸºå‡†æµ‹è¯•é‚®ä»¶\\nå‘é€æ—¶é—´: {datetime.now().isoformat()}"
            }
            
            response_time, success, result, error = self.measure_response_time(
                requests.post, f"{self.base_url}/api/send", json=email_data, timeout=30
            )
            
            response_times.append(response_time)
            
            if success and result.status_code == 200:
                success_count += 1
                print(f"âœ… é‚®ä»¶{i+1}: {response_time:.2f}ms - å‘é€æˆåŠŸ")
            else:
                error_count += 1
                error_msg = error or f"HTTP {result.status_code if result else 'Unknown'}"
                print(f"âŒ é‚®ä»¶{i+1}: {response_time:.2f}ms - {error_msg}")
            
            time.sleep(1)  # é‚®ä»¶å‘é€é—´éš”æ›´é•¿
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_time = statistics.mean(response_times) if response_times else 0
        
        email_result = {
            "iterations": iterations,
            "success_count": success_count,
            "error_count": error_count,
            "success_rate": (success_count / iterations) * 100 if iterations > 0 else 0,
            "avg_response_time": avg_time,
            "min_response_time": min(response_times) if response_times else 0,
            "max_response_time": max(response_times) if response_times else 0
        }
        
        self.results["email_tests"].append(email_result)
        
        self.log(f"ğŸ“Š é‚®ä»¶å‘é€ç»“æœ: æˆåŠŸç‡ {email_result['success_rate']:.1f}%, "
                f"å¹³å‡å“åº”æ—¶é—´ {avg_time:.2f}ms")
        
        return email_result
    
    def monitor_system_resources(self, duration=60):
        """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        self.log(f"ğŸ“Š ç›‘æ§ç³»ç»Ÿèµ„æº ({duration}ç§’)")
        
        resource_data = []
        start_time = time.time()
        
        while time.time() - start_time < duration:
            try:
                # CPUä½¿ç”¨ç‡
                cpu_percent = psutil.cpu_percent(interval=1)
                
                # å†…å­˜ä½¿ç”¨æƒ…å†µ
                memory = psutil.virtual_memory()
                
                # ç£ç›˜ä½¿ç”¨æƒ…å†µ
                disk = psutil.disk_usage('/')
                
                # ç½‘ç»œç»Ÿè®¡
                network = psutil.net_io_counters()
                
                resource_info = {
                    "timestamp": datetime.now().isoformat(),
                    "cpu_percent": cpu_percent,
                    "memory_percent": memory.percent,
                    "memory_used_gb": memory.used / (1024**3),
                    "memory_total_gb": memory.total / (1024**3),
                    "disk_percent": (disk.used / disk.total) * 100,
                    "disk_used_gb": disk.used / (1024**3),
                    "network_bytes_sent": network.bytes_sent,
                    "network_bytes_recv": network.bytes_recv
                }
                
                resource_data.append(resource_info)
                
                if len(resource_data) % 10 == 0:  # æ¯10ç§’è¾“å‡ºä¸€æ¬¡
                    print(f"ğŸ“Š èµ„æºç›‘æ§: CPU {cpu_percent:.1f}%, "
                          f"å†…å­˜ {memory.percent:.1f}%, "
                          f"ç£ç›˜ {resource_info['disk_percent']:.1f}%")
                
            except Exception as e:
                self.log(f"èµ„æºç›‘æ§é”™è¯¯: {e}", "ERROR")
                break
        
        self.results["resource_usage"] = resource_data
        
        if resource_data:
            avg_cpu = statistics.mean([r["cpu_percent"] for r in resource_data])
            avg_memory = statistics.mean([r["memory_percent"] for r in resource_data])
            
            self.log(f"ğŸ“Š èµ„æºä½¿ç”¨æ‘˜è¦: å¹³å‡CPU {avg_cpu:.1f}%, å¹³å‡å†…å­˜ {avg_memory:.1f}%")
        
        return resource_data
    
    def run_full_benchmark(self):
        """è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•"""
        self.log("ğŸ§ª å¼€å§‹é‚®ç®±æœåŠ¡å™¨åŸºå‡†æµ‹è¯•")
        self.log(f"ç›®æ ‡æœåŠ¡å™¨: {self.base_url}")
        
        # 1. åŸºç¡€APIæµ‹è¯•
        print("\n" + "="*50)
        print("ğŸ“¡ åŸºç¡€APIæ€§èƒ½æµ‹è¯•")
        print("="*50)
        
        self.test_api_endpoint("/api/mailboxes", "GET", iterations=20)
        
        # æµ‹è¯•è®¤è¯API
        auth_data = {
            "email": "admin@ygocard.org",
            "password": "admin123"
        }
        self.test_api_endpoint("/api/auth/login", "POST", auth_data, iterations=10)
        
        # 2. é‚®ä»¶å‘é€æµ‹è¯•
        print("\n" + "="*50)
        print("ğŸ“§ é‚®ä»¶å‘é€æ€§èƒ½æµ‹è¯•")
        print("="*50)
        
        self.test_email_sending(iterations=5)
        
        # 3. å¹¶å‘æµ‹è¯•
        print("\n" + "="*50)
        print("ğŸš€ å¹¶å‘æ€§èƒ½æµ‹è¯•")
        print("="*50)
        
        self.test_concurrent_requests("/api/mailboxes", concurrent_users=10, requests_per_user=5)
        self.test_concurrent_requests("/api/mailboxes", concurrent_users=20, requests_per_user=3)
        
        # 4. ç³»ç»Ÿèµ„æºç›‘æ§ï¼ˆåœ¨åå°è¿è¡Œï¼Œæ—¶é—´è¾ƒçŸ­ï¼‰
        print("\n" + "="*50)
        print("ğŸ“Š ç³»ç»Ÿèµ„æºç›‘æ§")
        print("="*50)
        
        # åœ¨åå°å¯åŠ¨èµ„æºç›‘æ§
        import threading
        monitor_thread = threading.Thread(target=self.monitor_system_resources, args=(30,))
        monitor_thread.start()
        
        # åŒæ—¶è¿›è¡Œä¸€äº›APIè¯·æ±‚ä»¥äº§ç”Ÿè´Ÿè½½
        self.test_concurrent_requests("/api/mailboxes", concurrent_users=15, requests_per_user=10)
        
        # ç­‰å¾…ç›‘æ§å®Œæˆ
        monitor_thread.join()
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        self.log("ğŸ“‹ ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        
        total_time = time.time() - self.start_time
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        all_api_tests = self.results["api_tests"]
        all_concurrent_tests = self.results["concurrent_tests"]
        all_email_tests = self.results["email_tests"]
        
        summary = {
            "test_duration": total_time,
            "total_api_tests": len(all_api_tests),
            "total_concurrent_tests": len(all_concurrent_tests),
            "total_email_tests": len(all_email_tests),
            "avg_api_response_time": 0,
            "avg_api_success_rate": 0,
            "max_throughput": 0,
            "avg_email_response_time": 0
        }
        
        if all_api_tests:
            summary["avg_api_response_time"] = statistics.mean([t["avg_response_time"] for t in all_api_tests])
            summary["avg_api_success_rate"] = statistics.mean([t["success_rate"] for t in all_api_tests])
        
        if all_concurrent_tests:
            summary["max_throughput"] = max([t["throughput"] for t in all_concurrent_tests])
        
        if all_email_tests:
            summary["avg_email_response_time"] = statistics.mean([t["avg_response_time"] for t in all_email_tests])
        
        self.results["summary"] = summary
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"results/benchmark_report_{timestamp}.json"
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(self.results, f, indent=2, ensure_ascii=False)
            
            self.log(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        except Exception as e:
            self.log(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}", "ERROR")
        
        # æ§åˆ¶å°è¾“å‡ºæ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ“Š åŸºå‡†æµ‹è¯•æŠ¥å‘Šæ‘˜è¦")
        print("="*60)
        print(f"æµ‹è¯•æ€»æ—¶é•¿: {total_time:.2f}ç§’")
        print(f"APIæµ‹è¯•æ•°é‡: {summary['total_api_tests']}")
        print(f"å¹¶å‘æµ‹è¯•æ•°é‡: {summary['total_concurrent_tests']}")
        print(f"é‚®ä»¶æµ‹è¯•æ•°é‡: {summary['total_email_tests']}")
        print(f"å¹³å‡APIå“åº”æ—¶é—´: {summary['avg_api_response_time']:.2f}ms")
        print(f"å¹³å‡APIæˆåŠŸç‡: {summary['avg_api_success_rate']:.1f}%")
        print(f"æœ€å¤§ååé‡: {summary['max_throughput']:.2f} req/s")
        print(f"å¹³å‡é‚®ä»¶å‘é€æ—¶é—´: {summary['avg_email_response_time']:.2f}ms")
        
        if self.results["resource_usage"]:
            resource_data = self.results["resource_usage"]
            avg_cpu = statistics.mean([r["cpu_percent"] for r in resource_data])
            avg_memory = statistics.mean([r["memory_percent"] for r in resource_data])
            print(f"å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
            print(f"å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.1f}%")
        
        print("="*60)
        print("âœ… åŸºå‡†æµ‹è¯•å®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥ä¾èµ–
    try:
        import requests
        import psutil
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {e}")
        print("è¯·å®‰è£…: pip install requests psutil")
        sys.exit(1)
    
    # åˆ›å»ºç»“æœç›®å½•
    os.makedirs("results", exist_ok=True)
    
    # è¿è¡ŒåŸºå‡†æµ‹è¯•
    benchmark = MailServerBenchmark()
    
    try:
        benchmark.run_full_benchmark()
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        benchmark.generate_report()
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        benchmark.generate_report()

if __name__ == "__main__":
    main()